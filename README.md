### 案件概要

社会保険系法人様の業務システムの大幅刷新案件(運用プラットフォームの AWS 移行、サービスのサーバレス化、運用自動化)

### 担当

テストチームに早期から参画し、案件序盤ではテスト自動化や CI/CD 手法の考案と検証を担当しました。

案件中盤からは、上記の考案に基づいたサンプルプロジェクトやテスト実施ガイドの作成や、上記以外にテストチームの作業で必要な AWS リソースの検討や、それらの利用フローや使用方法をドキュメント化する作業を担当していました。

テストフェーズ開始後は、 Selenium(Python) テストコードの作成とレビュー、テスト実施を担当しました。

### 作業実績

AWS におけるクラウド戦略でいうところの「リファクタリング」戦略に相当する、ほぼ新規開発の案件に序盤から参画しました。自分が案件に参画した時点で仕事（今回の場合「テスト」）の進め方が決まっていない状況が初めて、かつ、「自動化したテスト手法を考えてほしい」と頼まれた時は、かなり戸惑いましたが、必死に調査を進めて提案を練り上げ、それらの提案が（全て採用された訳ではありませんでしたが）受け入れられ、プロジェクト全体で実践されていく、という体験はとても面白く実力もついたと思います。特に心に残ったことを以下に記載します。

#### CI の提案

参画後、最初に手掛けた仕事は「単体・結合テスト自動化」をどのように実現するかを考案することでした。単体テスト(Python)に関しては、「スタブ DB 」案と「Mock コード」案の 2 択を技術コンサルチームの方に提案したところ、動作パフォーマンスの観点から後者がよいと助言を受け、結合テストに関しては、PM の方から「Selenium のようなソフトウェアを使ってやりたいと考えている」との要望を受けていました。これらの状況を検討し、また前提として、リソース（ソースコード（CodeCommit）やアプリ（Lambda））は AWS 上に集約させる、とのことだったので、AWS CodePipeline/CodeBuild を使用した単体テストと結合テストを考案しました。単体テストは nose(Python のテストフレームワーク), 結合テストは Selenium WebDriver をそれぞれ CodeBuild 内のサーバーで動かすことで CI を実現する、というものでしたが、「ビジネス要件で、アプリリソース以外は AWS 上に置かない(CI は運用/インフラリソースという扱い)」と後に決まってしまい、それぞれ、テスト手法はそのままで、動作環境をライブラリ管理者やテスターのローカル端末に変更した構成での実施となりました。

#### テストチームにおける、AWS リソース利用の窓口・ドキュメント作成

テストチームとして最終的には 10 名以上のメンバーが集まりましたが、AWS について少しでも知見のあるメンバーは自分 1 人という状況だったので、テストに必要な AWS リソースの利用について上位ベンダーの方と検討したり(Redmine チケット上や Teams, 対面での打ち合わせ)、それらの使い方やデータ投入方法（例えば、 Cognito の ユーザーやプロパティの追加方法だったり、AWS CLI をインストールして開発用ロールを使うための設定だったり）を調査してテストチームメンバー向けに説明したり、ドキュメント化して回ったので、 AWS リソースについて広く知見を貯められたかなと思います。

#### 反省点(CD について)

(保守フェーズを見据えてだと思いますが)デプロイについては、管轄が自分の手から離れてしまっていました。実際に開発中にされていた運用は、担当者のローカル端末でソースコードを clone し何らかの作業を行った上でデプロイするものでした。これらは Git の操作ミスなどに起因するデプロイミスを誘発し、また、一部の特殊なデプロイに関しては、故障対応後の再デプロイの際に時間がかかったりデプロイミスが起こっていました。また、デプロイ知識や手法が属人化してしまうことで、担当者の離任後に引き継ぎ者によるデプロイがうまくいかず、トラブルシューティングに時間がかかってしまうなど、アンチパターンを実践する結果となっていました。

こちらについては、何らかの手段でデプロイ手順やデプロイするリソースの「コード化(IaC)と共有」によって再現性のあるデプロイを実行できていれば、上記のような失敗を防げたと考えています。今回の場合、 上記の通りのようにローカル環境からステージ環境のリソースを自由に扱える IAM ユーザーとロールが払い出されていたので、例えば、開発環境上に CodePipeline を構築し、ステージ環境の IAM ユーザーとロールのクレデンシャルで CodeBuild を動作させたり、あるいは 開発環境にライブラリ管理用の共有 EC2 を立てて、そこにデプロイ用のシェルやソースコードを配置し、同様にステージ環境のクレデンシャルで動作させるなど、何かしら手は打てたのかなと、振り返っています。

### 案件概要

不動産情報系サイト運営企業様の、toC メディアサービス基盤の AWS 移行案件

### 担当

クライント企業様内のユーザー部門向けツール(Web アプリ)の AWS 移行を担当しました。特にミッションクリティカルな要求はなく、現行アプリ自体も、1 つのサーバーに Web サーバー(IIS)/アプリ本体(PHP)/ユーザー管理 DB(MySQL) が同居しているような、ちょっとしたツールでした。なので、作業自体は自分 1 人で進めていました。

また、ツール移行作業完了後に余った契約期間は AWS 移行プロジェクト本体で、メディアサービス Web アプリ(フロントサーバー/PHP, API サーバー/Java)のテスト障害対応を行っていました。

### 作業実績

移行するにあたり、本体プロジェクトのリーダーの方からは、

- ミドルウェアを更新してほしい(Windows Server -> Amazon Linux 2, PHP4 -> PHP7.1)
- アプリ内の機能について整理し、使っていない機能のコードについては削除してほしい
- 最終的な成果物は AMI にしてほしい
- バックアップを定期的にとってほしい
- 監査用の操作ログをとる機能を追加してほしい
- 運用コスト(EC2 をホスティングする費用)が最小限になるように、スケジューリング起動してほしい

以上の要望を受けていました。

#### ソースコードリファクタリング

使っていない(現行で動かない)機能もあるとのことだったので、作業の全体を見通すために、ログイン画面を軽く直したあと並行してその整理を始めました。各機能が依存している DB について、移行状況や廃止状況を現場の詳しい方や本体プロジェクトのリーダーに確認し、不要そうな機能の洗い出しを行いました。その後、ユーザー部署担当の方に問い合わせを行い、使われていない機能については使用状況を確認の上、廃止する運びとなりました。多方面への確認と返答待ちが多かったですが、待ち期間にはメイン機能のフィックスを行うなどして、待ちの時間を作ることなく、効率よく作業を進められたかなと思います。

#### 追加機能

機能追加として、自動バックアップ機能を実装しました。まずバックアップ対象について検討した結果、定時バックアップ取得の必要なリソースは、本アプリ内に同居した MySQL DB と 操作/アクセスログ だけでした。また、 MySQL のデータについても、更新がまれで、かつ、行列数も非常に少なく、万が一消失したとしても手入力で十分対応できるレベルだったので、毎日定時のダンプ取得でよく、 EBS や AMI をまるごと世代管理するようなバックアップは不要とわかりました。なので、バックアップについては、毎日定時に MySQL のダンプを作成し、ログと一緒に S3 にアップロードする仕組みで対応しました(cron, AWS CLI, シェルスクリプトで作成しました)。

#### テスト

改修後の本アプリのテストについては、 Puppeteer という Node.js で動作するヘッドレス Chrome が扱えるライブラリを用いてコードによる E2E テストを行いました。これは、以前自分が参画していた案件で Selenium による E2E テストの実施が検討されていたことがきっかけで自動テストについて興味を持っていたところに、ちょうどテスト要件がマッチする本案件に参画できたので、この機会に使ってみて知見を貯めよう、ということで、自分から導入の提案をしたものでした。 Puppeteer を導入してみた感想は、テストスクリプトも書きやすく、動作も軽快で、なにより反復した文字入力やスクリーンショット取得を手作業で行わなくて済むので、ぜひ別の機会にも導入してみたいと思えるものでした。

#### メディアサービス案件のテスト故障対応

上記のアプリ移行の作業終了後は、メディアサービスプロジェクトでテスト故障チケットの対応を行いました。フロントエンドの PHP, API サーバーの Java ともに、抽象クラスなどを駆使した本格的なオブジェクト指向プログラミングに基づいたプロダクトだったので、これらにあまり触れることがなかった自分は最初はソースコード解読に時間がかかってしまっていましたが、設計書を読んだり、ローカルのソースコードにデバッガを仕込んで、画面操作と 起動する API サービス のひも付きを調査するなど、プログラミングの処理細部よりもサービスの処理フローと入出力を中心に覚えることで、対応速度が上がっていったと思います。

#### 余談

余談ですが、本メディアサービスのアーキテクチャー(Blue/Green 構成だったり、DB のリードレプリカを使用した負荷分散だったり)は、これまで自分が携わった案件の中で最も大規模で興味深く感じ、作業が暇なときはついつい設計書やインシデント報告書を読んで過ごしていました。自分はパブリッククラウド系の資格をいくつか取得しているのですが、この現場で働いている時に「自分もこのような環境で動くアプリを作れるようになりたい！(負荷分散やサービス連携の仕組みを考えてみたい)」と、思ったことが取得理由の 1 つです。

さらに余談ですが、つい先日、このときにお世話になったリーダーの方に、「また同じ案件で人を探してるいるんだけど、どうかな？」と声をかけていただけて、単純に嬉しかったです。

### 案件概要

資格取得が一服し、そろそろ身につけたり、日頃の情報収集で見聞きした技術について棚卸しとアウトプットが必要と感じました。また、題材として自分の好きなフロントエンドの技術を使いたかったので、新規にブログを作成することにしました(元々、エンジニアとしての入りがブログの作成(インフラ構築含む)だったこともあり、自分はフロントエンドとインフラの技術を好んでいます)。

### 使用技術

フロントエンド: TypeScript/Next.js/Apollo Client/S3(静的ホスティング)/Cloud Front
API サーバー: TypeScript/Apollo Server/Cloud Run
記事入稿システム: TypeScript/Python/Lambda/SQS/DynamoDB
IaC: AWS CDK/TypeScript
CI/CD: GitHub Actions

以下のリポジトリに環境構成図を作成したので、詳しく知りたい方がいましたらご参照いただければと思います。
https://github.com/fijixxx/sublog-architecture

### 工夫した点

今回、ブログを作成するにあたって、自分で以下の要件を設定しています。

- システムの拡張や修正がしやすいように、マイクロサービスを意識して構築すること
- 機能の開発や記事の入稿がしやすいように、 CI/CD の仕組みをしっかりやること
- 新しい技術をできるだけ盛り込むこと

それぞれ解説していくと、

- システムの拡張や修正がしやすいように、マイクロサービスを意識して構築すること

これはマイクロサービスの構成が流行しているからというのもあるのですが、できるだけ小さくつくってこまめにリリースすることを心がけることで、仕事やプライベートが忙しいときでも開発を続行したり、開発が中断しても続きから再開しやすくするためです(大きく開発すると、再開した時に「どこまでやってたんだっけ？」「どうやって作ってたんだっけ？」を思い出すのに時間がかかりがちになります)。

また、この文脈で技術選定をすると、開発にあたって型情報を利用できるものを選びたくなります。そういった理由で、開発言語については TypeScript を選定し、バックエンドとのインターフェースには Apollo(GraphQL) を使用しています。

- 機能の開発や記事の入稿がしやすいように、 CI/CD の仕組みをしっかりやること

これは開発や記事執筆にあたってのストレスをなるべく減らして、作業に集中するためには CI/CD をやる必要があると思って設定した要件です。機能や記事を書き上げた後、疲れた気持ちで煩雑なデプロイ作業を行うのは気が進みませんし、最悪デプロイ事故を招きます。また、マイクロサービスを運用するにあたって、散らばりがちな依存リソースを把握して管理することは、無駄な課金や思わぬセキュリティ事故を防ぐ観点からも重要です。

GitHub Actions, AWS CDK を使って CI/CD を実現しています。また、 CI/CD からは離れているかもしれませんが、 GitHub の issue や project を使って、タスク管理を行っています。

- 新しい技術をできるだけ盛り込むこと

技術について、(知っているだけでなく)触ってみて初めてわかる感覚的な知見があると思っています。
